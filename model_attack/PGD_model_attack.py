import torch
import torch.nn.functional as F
import pandas as pd
import torch.nn as nn
import numpy as np
import torch.nn.functional as F
from prepare_models import model_list
from prepare_datasets import min_test_loader, test_loader
from PIL import Image
import torchvision.transforms as transforms
device = 'cuda' if torch.cuda.is_available() else 'cpu'

def pgd_attack(model, images, labels, epsilon, alpha, num_steps, norm='inf'):
    """
    PGD Attack function.
    
    Arguments:
    - model: The model being attacked.
    - images: The input images (batch of samples).
    - labels: The true labels corresponding to the images.
    - epsilon: The maximum perturbation allowed (for L_infinity norm).
    - alpha: The step size for each iteration.
    - num_steps: The number of iterations to run the attack.
    - norm: The norm to use for the perturbation ('inf' for L_infinity, '2' for L2 norm).
    Returns:
    - perturbed_images: The adversarial images generated by the attack.
    """
    # Ensure the model is in evaluation mode
    model.eval()

    # Make a copy of the input images and require gradients
    
    perturbed_images = images.clone().detach().to(device).requires_grad_(True)

    # Loop through the number of steps
    for _ in range(num_steps):
        # Zero the gradients before the backward pass
        model.zero_grad()
        # Get the model's output
        outputs = model(perturbed_images)
        # Calculate the loss (cross-entropy loss)
        loss = F.cross_entropy(outputs, labels)
        # Compute gradients
        loss.backward()
        
        # Update the perturbation
        with torch.no_grad():
            if norm == 'inf':
                # L_infinity norm perturbation
                perturbation = alpha * perturbed_images.grad.sign()
                perturbed_images = perturbed_images + perturbation
                # Clip the perturbation to ensure it stays within the epsilon ball
                perturbed_images = torch.max(torch.min(perturbed_images, images + epsilon), images - epsilon)
            elif norm == '2':
                # L2 norm perturbation
                perturbation = alpha * perturbed_images.grad / perturbed_images.grad.view(perturbed_images.size(0), -1).norm(p=2, dim=1).view(-1, 1, 1, 1)
                perturbed_images = perturbed_images + perturbation
                # Project back to L2 ball
                delta = perturbed_images - images
                delta_norm = delta.view(delta.size(0), -1).norm(p=2, dim=1).view(-1, 1, 1, 1)
                delta = delta / delta_norm * epsilon
                perturbed_images = images + delta
            
        # Zero the gradients after each step
        perturbed_images.grad.zero_()
    return perturbed_images

def attack_model_cluster(models, images, labels, epsilon, alpha, num_steps, norm='inf'):
    """
    Attack a model cluster using PGD attack and return the combined output.
    """
    # 确保所有模型在设备上并启用参数梯度
    for model in models:
        model.to(device)
        model.eval()
        for param in model.parameters():
            param.requires_grad = True
    # 初始化对抗样本，启用梯度跟踪
    perturbed_images = images.clone().detach().to(device).requires_grad_(True)
    # 进行攻击
    for _ in range(num_steps):
        # 清零对抗样本的梯度
        # if perturbed_images.grad is not None:
        #     perturbed_images.grad.zero_()

        # 累计损失
        total_loss = 0
        for model in models:
            outputs = model(perturbed_images)
            # print(type(outputs))
            total_loss += F.cross_entropy(outputs, labels)

        # 反向传播
        total_loss.backward()

        # 更新对抗样本
        with torch.no_grad():
            if norm == 'inf':
                perturbation = alpha * perturbed_images.grad.sign()
                perturbed_images = perturbed_images + perturbation
                perturbed_images = torch.max(torch.min(perturbed_images, images + epsilon), images - epsilon)
            elif norm == '2':
                perturbation = alpha * perturbed_images.grad / (
                    perturbed_images.grad.view(perturbed_images.size(0), -1).norm(p=2, dim=1).view(-1, 1, 1, 1) + 1e-12)
                perturbed_images = perturbed_images + perturbation
                delta = perturbed_images - images
                delta_norm = delta.view(delta.size(0), -1).norm(p=2, dim=1).view(-1, 1, 1, 1)
                delta = delta / delta_norm * epsilon
                perturbed_images = images + delta

    # 计算模型集群的最终输出
    outputs = []
    for model in models:
        output = model(perturbed_images)
        outputs.append(output)

    final_outputs = torch.mean(torch.stack(outputs), dim=0)
    return outputs, perturbed_images, final_outputs


def calculate_accuracy(outputs, labels):
    """
    Calculate the accuracy of the model's predictions.
    """
    _, predicted = torch.max(outputs, 1)  # 获取每个样本的最大预测值的索引
    correct = (predicted == labels).sum().item()  # 计算正确预测的数量
    accuracy = correct / labels.size(0)  # 精确度 = 正确预测 / 样本总数
    return accuracy


images, labels = next(iter(min_test_loader))

images = images.to(device)
labels = labels.to(device)
# decide some hypemeter
epsilon = 0.05
alpha = 0.01
num_steps = 20

submodel_outputs, adversarial_images, final_outputs = attack_model_cluster(models=model_list, images=images, labels=labels, epsilon=epsilon, alpha=alpha, num_steps=num_steps, norm='inf')

accuracy = calculate_accuracy(final_outputs, labels)

print(f"经过一般的PGD攻击，模型的分类精确度为:{accuracy}")
# save the adversarial_images 
unnormalize = transforms.Normalize(mean=[-0.485 / 0.229, -0.456 / 0.224, -0.406 / 0.225], std=[1 / 0.229, 1 / 0.224, 1 / 0.225])
def save_images(images, prefix='adversarial_image'):
    for i, img in enumerate(images):
        img = unnormalize(img)  # 反标准化
        img = img.permute(1, 2, 0).cpu().numpy()  # 转换为 NumPy 数组
        img = np.clip(img, 0, 1)  # Clip to [0, 1] range
        # 转换为 PIL 图像
        pil_img = Image.fromarray((img * 255).astype(np.uint8))
        # 保存为图像文件
        pil_img.save(f"{prefix}_{i}.png")
# 保存 adversarial_images 为图像文件
save_images(adversarial_images, 'adversarial_image')
# save the final_putputs
final_outputs_df = pd.DataFrame(final_outputs.cpu().numpy())
final_outputs_df.to_csv('final_outputs.csv', index=False)


